import os
import google.generativeai as genai
from openai import OpenAI

# üî± ‡∞Æ‡±Ä ‡∞∞‡±à‡∞≤‡±ç‡∞µ‡±á ‡∞µ‡±á‡∞∞‡∞ø‡∞Ø‡∞¨‡±Å‡∞≤‡±ç‡∞∏‡±ç ‡∞™‡±á‡∞∞‡±ç‡∞≤‡∞ï‡±Å ‡∞§‡∞ó‡±ç‡∞ó‡∞ü‡±ç‡∞ü‡±Å‡∞ó‡∞æ ‡∞Æ‡∞æ‡∞∞‡±ç‡∞ö‡∞æ‡∞®‡±Å
gemini_key = os.environ.get("GEMINI_KEY")
groq_key = os.environ.get("GROQ_KEY")
openrouter_key = os.environ.get("OPENROUTER_KEY")

# üß† Gemini
if gemini_key:
    genai.configure(api_key=gemini_key)
    gemini_model = genai.GenerativeModel('gemini-pro')
else:
    gemini_model = None

# üß† Groq (Grok ‡∞¨‡∞¶‡±Å‡∞≤‡±Å ‡∞Æ‡±Ä‡∞∞‡±Å Groq ‡∞µ‡∞æ‡∞°‡±Å‡∞§‡±Å‡∞®‡±ç‡∞®‡∞ü‡±ç‡∞ü‡±Å‡∞®‡±ç‡∞®‡∞æ‡∞∞‡±Å)
groq_client = OpenAI(api_key=groq_key, base_url="https://api.groq.com/openai/v1") if groq_key else None

# üß† OpenRouter (GPT ‡∞ï‡±ã‡∞∏‡∞Ç)
openrouter_client = OpenAI(api_key=openrouter_key, base_url="https://openrouter.ai/api/v1") if openrouter_key else None

def process_request(command):
    command = command.lower().strip()
    
    # ‚ö° ‡∞Æ‡±á‡∞ß‡∞∏‡±ç‡∞∏‡±Å ‡∞Ü‡∞¶‡±á‡∞∂‡∞æ‡∞≤‡±Å
    if command.startswith("ask arkon"):
        return ask_ai_brain(command.replace("ask arkon", ""), "gemini")
    elif command.startswith("ask groq"):
        return ask_ai_brain(command.replace("ask groq", ""), "groq")
    elif command.startswith("ask gpt"):
        return ask_ai_brain(command.replace("ask gpt", ""), "openrouter")
    
    # üîç ‡∞∏‡±ç‡∞ü‡±á‡∞ü‡∞∏‡±ç ‡∞ö‡±Ü‡∞ï‡±ç
    elif "status" in command:
        s = f"üî± ARKON STATUS: Gemini:{'ON' if gemini_model else 'OFF'}, "
        s += f"Groq:{'ON' if groq_client else 'OFF'}, OpenRouter:{'ON' if openrouter_client else 'OFF'}"
        return s
    
    return "ARKON: Command not recognized. Use 'status' or 'ask arkon/groq/gpt'."

def ask_ai_brain(prompt, brain_type):
    try:
        sys_p = "You are Arkon, a loyal AI protector for Leela Krishna's Xarvex mission."
        if brain_type == "gemini" and gemini_model:
            return f"üî± ARKON (Gemini): {gemini_model.generate_content(f'{sys_p} {prompt}').text}"
        elif brain_type == "groq" and groq_client:
            res = groq_client.chat.completions.create(model="llama3-8b-8192", messages=[{"role": "user", "content": f"{sys_p} {prompt}"}])
            return f"üî± ARKON (Groq): {res.choices[0].message.content}"
        elif brain_type == "openrouter" and openrouter_client:
            res = openrouter_client.chat.completions.create(model="openai/gpt-3.5-turbo", messages=[{"role": "user", "content": f"{sys_p} {prompt}"}])
            return f"üî± ARKON (GPT): {res.choices[0].message.content}"
        return "‚ùå ERROR: Core not configured."
    except Exception as e:
        return f"‚ùå NEURAL GLITCH: {str(e)}"
